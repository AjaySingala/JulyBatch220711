Data Warehousing:
=================
What is a Data Warehouse (DW)?
It is a repository (some kind of a DB) of current and historical information.
It is designed to enchance the performance of an organization / enterprise.
	- Optimizing processes.
	- Predicting trends
	- Determining current performance
	Performance ===> increased productivity, increased revenue/sales, increased profits, decreased cost.
	
The data in this DW is pulled from many sources - database, external partner system, customer-facing application, etc.
For e.g.; Sales data. Sources would be internal applications like Sales, Marketing, Finance, ecommerce application, any external systems (like suppliers etc.).

Key characterstics of DW:
-------------------------
Is a
- Subject-oriented,
- Integrated,
- Time-variant,
- Non-volatile
collection of data, which supports the management's decision making process.

Subject-oriented:
-----------------
DW is subject-oriented because it provides topic-wise information, rather than the overall process of a business.
Subjects like sales, inventory, marketing/promotions etc.
If you want to do some analysis of your company's sales data, you will have to build a DW that concentrates on Sales.
"Who was your best customer in the last year?"
"Who would likely be your best customer next year?"

Data vs Information:
--------------------
We derive information from data.
Data is in raw form. Information is when you create some context from the data (more organized).

So, from an ecommerce site, all order details captured is the "data".
Then, you take this data, cleanse it or filter it, and only take that data that can help you perform some analysis.
	Things like which products, which customers, how much quantity (and their price), which region (of customers), when (date-time).
You will take these "data elements" and store them in a DW on a regular basis (not real-time).
Once you have this data, you process it. This will give you "information" that will help you determine current position of your comapny and also enable you to identify trends and come up with forecasts.
Decisions are taken based on the information that comes out from the data.

Integrated:
-----------
A DW is developed by getting (integrating) data from various sources and not necessarily just one DB (data source).
And the data has to be in a consistent format.
The data that is stored in the DW must be in a consistent format and stored in a manner that is acceptable universally (accepted by all stakeholders) in terms of naming conventions, coding.
Facilitates effective data analysis.

Non-Volatile:
-------------
Volatile == change (how often does it change).
Operational updates of data do not occur on the DW, updates, insert, delete ops.
The DW should always be "updated" only via the ETL job sitting b/w the live DB and the DW.
	OLTP -> OnLine Transaction Processing ==> Live DV
	OLAP -> OnLine Analytical Processing  ==> DW
Data once entered in the DW must remain unchanged.
All data is read-only.
Previous data is not erased when new (current) data captured / entered.

Time-Variant:
-------------
The data stored in a DW is documented with an element of time.
Any data stored in the DW must have an element of time like the day, week, month or year.

Since DW stores historical data, if this data is time-variant, you can retrieve data/files from 3 months, 6 momths, 12 months or even any previous data from the DW.

What is the need of a DW?:
--------------------------
1. Business Users: they require the DW to view summarized data from the past. Non-technical. The data is presented to them as information in a very elementary form (in a visual format).
2. Store historical data: DW is required to store time variable data from the past.
3. Make strategic decisions: Some strategies may depend upon the data stored in the DW. So, DW contributes to making of strategic decisions.
4. For data consistency and quality: Inability to delete/update/insert data addes to quality & consistency. Bringing the data in the DW (common place) from different sources, but storing it in a single recognized format. The user can effectively bring uniformity and consistency in the data.
5. High response time: DW has to be ready for unexpected loads and the types of queries that will be executed. This demands a significant degree of flexibility and quick response time.

Database (OLTP, Operational DB) vs Data Warehouse (OLAP):
=========================================================
1. DB involves day-to-day processing. DW involves historical processing of information.
2. DB are OLTP sytems used by clerks, DBAs, or DB professionals. DW are OLPA systems used by knowledge workers like executives, managers, analysts etc.
3. DB is used to run the business. DW is used to analyze the business.
4. DB focuses on Data in. DW focuses on Information out.
5. DB is based on ERM (Entity Relationship Model) on which you create ERDs (Entity Relationship Diagrams). DW is based on Star Schema, Snowflake Schema etc.
6. DB is application oriented. DW is designed keeping in mind the information to be generated.
7. DB contain current data. DW can contain current as well as historical data.
8. DB provides flat relational view of the data. DW provides summarized and multidimensional view of the data.
9. DB the no. users could be in thousands. DW the no. could possibly be in the hundreds.
10. DB the no. of records accessed is in tens-of-thousands. DW the no. of records accessed is in millions.
11. DB designed keeping in mind the performance of the application generating / using the data. DW is designed keeping mind the flexibility of generating the information in a timely manner.

Types of DWs:
-------------
- Enterprise DW (EDW).
	- Serves as the central database that facilitates decision-support services of the enterprise.
	- Gives access to cross-organizational information.
- Operational DW System (ODS).
	- Refreshes in real-time. Storing employee records.
- Data Mart (DM).
	- A subset of DW built to maintain a particular department or region or business unit.
	- Every "unit" (dept., region etc.) will have a central repo of it's own - data mart.
	- The data is refreshed periodically.
	
The data from the DM is stored in the ODS periodically. Then the ODS sends the data to the EDW, where it is stored and used at the org level for enterprise-wide strategic decisions.

DW Tools:
---------
These are nothing by software components used to perform operations on huge data sets.
They help to collect, read, write and transfer data from various sources.
DW application categories:
- Query and reporting tools.
- Application development tools.
- Data mining tools.
- OLAP tools.

Functions of DW:
----------------
- Data Extraction - gathering data from different sources.
- Data Cleaning - finding and correcting errors in data.
- Data Transformation - converting the data from legacy (or OLTP sources) to warehouse format.
- Data Loading - sorting, summarizing, consolidating, checking integrity, creating partitions etc.
- Refreshing - Updating data from various sources at regular intervals.

Benefits of DW:
---------------
Improved data consistency.
Better business decisions.
Easier access to enterprise data to end-users (central repo).
Better documentation of the data (data mapping).
Reduce costs and improve productivity.
Enable end-users to run ad-hoc queries or reports without affecting the performance of the operational system (RDMBS, OLTP).
Collection of related data from various sources into a single common place.

DW Archiretecture with a single DW.
DW Archiretecture with a staging area.
DW Archiretecture with a staging area and Data Marts.

10-Aug-2022:
============
ETL Process:
============
Extraction, Transaction and Loading.
It is the mechanism to extract info/data from source systems and bring it into the DW.
How ETL works?:
---------------
1. Extraction: The operation of extracting / fetching data from source system(s) to be used and processed in the DW.
	It is possible that the source system might be complicated and there could be lack of documentation of the data to be extracted.
	It becomes difficult to determine the data required to be extracted.
2. Cleansing: A very crucial stage in ETL because it improves the quality of the data.
3. Transformation: Convert the source data into a format that is recognizeable by the DW.
4. Loading: This process is where the data is written to the target DB (DW). It is very important to ensure that the load is performed properly, and with with as little resources as possible.
	Can be done in 2 ways:
		i. Refresh: DW is completely rewritten. Older files/data are replaced with newer ones.
		ii. Update: Only changes applied (or done) to the source system are added to the DW (a.k.a. an incremental update).

You can also do an ELT: Extract, Load & Transform.

Data Mart:
==========
A Data Mart (DM) is a subset of the entire data set that you have, usually oriented to a specific purpose (primary subject).
For e.g.; for a specific department, business unit, community, region, country.
DMs are derived from the data that exists in the DW or you can directly create the DMs and then use them further in the EDW.

The fundamental use of a DM is Business Intelligence (BI) applications.
BI used to gather, store, access and analyze records.
Can be used by smaller businesses / units as it becomes less expensive than implementing a full-fledged DW.

Reasons for creating a DM:
- Created by a specific group of users.
- Easy access to the frequently required data.
- Easy to create.
- Improves end-user response time.
- Lower cost than implementing a complete DW.
- Less cluttered as it has only essential business data.

ETL and Big Data:
=================
When working with Big Data, we do end up using ETL in some form or the other.
Tools in Big Data (Hadoop) for ETL:
1. Load data into HDFS.
2. Use Hadoop Pig to transform the data in HDFS.
3. Load data into a Hive-based DW.
	- Hive is not a DB (is not a RDBMS!!!).
	- Hive is a Distributed DW!
4. Perform further ETL aggregations in Hive.
5. Leverage Sqoop to integrate RDBMS with Hadoop.

There is also Apache HBase, Apache Flume, Apache Oozie, Apache Zookeeper.

Apart from these, you can also use Spark and Kafka.

Hadoop is not an ETL Tool. It is an ETL Helper.

Dimensional Modeling:
=====================
RDBMS: we do ERD / ERM (Entity Relationship Modeling)
DW: Dimensional Modeling (DiMo).

DiMo represents data with a "cube operation", to enable the data to be viewed and anazlyed from different angles/sides/views.
DiMo was developed by Ralpha Kimball.
DiMo consists of "facts" and "dimensions".

The transaction record is divided either into "facts", which are basically numerical txn data or into "dimensions". which are reference information that gives context to the fact.

For e.g.; a Sale Txn: can be divided into:
	- facts such as the number of products ordered and the price paid for the products.
	- dimensions such as Order Date, username, product number, bill-to / ship-to locations, salesman responsible for the order.
	
Facts are the data that you want to perform the analysis on.
Dimensions are the references based on which you analyze the facts.

Select ProductId, ProductName, City, SUM(Qty) as 'TotalQuantity';, SUM((Qty * Price) as 'TotalAmount')
FROM dw
WHERE City = 'Seattle'
AND OrderDate BEWTEEN '2022-01-01' AND '2022-06-30'
GROUP BY ProductId, ProductName, City

Measure: It is a numeric attribute of a fact, which represents the performance or behavior of the business relative to the dimension.

For the "facts", we create "Fact Tables".
For the "dimensions", we create "Dimension Tables".

Fact Table:
-----------
Includes numerical values of what we measure.
Each Fact Table includes "keys" to be associated with dimension tables. These keys are known as "foreignb keys" in the fact table.
Typically, fact tables have a small number of columns.
Compared to a dimension table, fact tables have a large number of rows.

Dimension Table:
----------------
Establish the context of the facts.
Store the fields that describe the facts.

Multi-Dimensional Data Model: When you have more than 1 Dimension tables.

Star Schemas:
-------------
We have de-normalized DB that can quickly provide query responses.


Snowflake Schema:
-----------------
When Dim tables have references to other Dim tables.

Data Cube:
==========
3-D Cube or 3-Dimensional Cuboid.

Slowly Changing Dimensions (SCD):
=================================
Are the dims in which the data changes slowly rather than regulary on a time basis.

SCD Types:
----------
Type 0: A Fixed Dim. Changes to the data are not allowed.
Type 1: Maintains only the current state. No historical is allowed. Changes to the data are updated.
Type 2: History is maintained. All changes to the data are recorded and stored.
Type 3: Only the current state and previous state are maintained.
Type 4: Maintain only the current state in this Dim table and record all other changes in another table.
Type 5: Hybrid. Combo of 1, 2 and 3 to track all changes to the data.

Typically, types 1, 2 and 3 are used.

Type 2 is most commonly used.
Type 2 SCD:
	- Versioning: 1,2,3 or 0.1, 0.2, 0.3.
	- Flags: 0, 1 
		customer's current country is USA, so the record will be flagged as:
			Id	CustomerId	Name		Country		Flag
			1	101			John Smith	USA			1
		customer oves to Canada. So the records will be as:
			Id	CustomerId	Name		Country		Flag
			1	101			John Smith	USA			0
			2	101			John Smith	USA			1
	- Effective date: there will be a start and end date to the records:
			Id	CustomerId	Name		Country		start_date	end_date
			1	101			John Smith	USA			1999-03-15	2022-02-16
			2	101			John Smith	Canada		2022-02-17	9999-12-12

		
Conformed Dimensions:
=====================
A Conformed Dimension (CD) is a dim that has exactly the same meaning and content when being referred from different fact tables.
A CD can refer to multiple tables in multiple data marts within the same organization.

2 Dim tables, both having country data:
Dim_country_1
101	USA
102 Canada
103	Mexico
104	UK

Dim_Country_2
101	Mexico
102	USA
103	UK
104 Canada

Dim_Country_3
101	USA
102 Canada
103	Mexico
104	UK

If the data in 2 dims tables is exactly the same except for the PK, they are not considered to be CDs.
In the above example, _1 and _3 are CDs.

The "time" is a common CD in any organization.
The year 2022 will never be 2021.
16th Oct will never be identified as 15th Oct.

Fiscal Year vs Calendar year.
Fiscal Year could Apr to Mar.
Calender Year could be Jan to Dec.
Just create 2 diff conformed dims (tables).

Data Mapping (document):
========================
What is Data Mapping?:
----------------------
It is the process of taking one set of data (source - RDBMS) and assign (map) it to it's destination (target - DW).
The goal of Data Mapping is to make your org's data more structured and accessible to teams or customers or partners.

Data Mapping Document is where you record each and every source field, how does it map to all other target application's fields.

Steps for Data Mapping:
1. Identify all data fields that must be mapped.
2. Standardize naming conventions across sources.
3. Create data transformation rules and schema logic.
4. Test your logic.
5. Complete the migration, integration or transformation.
